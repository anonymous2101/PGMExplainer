{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import networkx as nx\n",
    "from torchvision import datasets as ds\n",
    "from torchvision import transforms\n",
    "import argparse\n",
    "\n",
    "from nets.superpixels_graph_classification.load_net import gnn_model # import all GNNS\n",
    "from data.data import LoadData # import dataset\n",
    "from utils import GCN_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Loading dataset MNIST...\n",
      "train, test, val sizes : 55000 10000 5000\n",
      "[I] Finished loading.\n",
      "[I] Data load time: 48.0152s\n"
     ]
    }
   ],
   "source": [
    "MNIST_test_dataset = ds.MNIST(root='PATH', train=False, download=True, transform=transforms.ToTensor())\n",
    "MODEL_NAME = 'GCN'\n",
    "DATASET_NAME = 'MNIST'\n",
    "dataset = LoadData(DATASET_NAME)\n",
    "trainset, valset, testset = dataset.train, dataset.val, dataset.test\n",
    "\n",
    "net_params = GCN_params.net_params()\n",
    "model = gnn_model(MODEL_NAME, net_params)\n",
    "model.load_state_dict(torch.load(\"data/superpixels/epoch_188.pkl\"))\n",
    "model.eval()\n",
    "\n",
    "test_loader = DataLoader(testset, batch_size=1, shuffle=False, drop_last=False, collate_fn=dataset.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnnExplainer import explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhvu/myroot/lib/python3.6/site-packages/dgl/base.py:25: UserWarning: Currently adjacency_matrix() returns a matrix with destination as rows by default.  In 0.5 the result will have source as rows (i.e. transpose=True)\n",
      "  warnings.warn(msg, warn_type)\n"
     ]
    }
   ],
   "source": [
    "index_to_explain = [0]\n",
    "Explanations = []\n",
    "for iter, (graph, label, snorm_n, snorm_e) in enumerate(test_loader):\n",
    "    if iter in index_to_explain:\n",
    "        g = graph\n",
    "        l = label\n",
    "        pred = model.forward(g, \n",
    "                             g.ndata['feat'],\n",
    "                             g.edata['feat'],\n",
    "                             snorm_n, \n",
    "                             snorm_e)\n",
    "        adj = g.adjacency_matrix().to_dense()\n",
    "        feat = g.ndata['feat']\n",
    "        norm_n = snorm_n\n",
    "        norm_e = snorm_e\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_ = np.expand_dims(adj, axis=0)\n",
    "feat_ = np.expand_dims(feat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_torch = torch.tensor(adj_, dtype=torch.float)\n",
    "x_torch = torch.tensor(feat_, requires_grad=True, dtype=torch.float)\n",
    "l_torch = l.clone().detach()\n",
    "pred_label = np.argmax(pred[0].detach().numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = ExplainModule(g, model, l_torch,\n",
    "                         x_torch, g.edata['feat'],\n",
    "                         norm_n, norm_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.0067e-12, 4.6651e-08, 9.9997e-01, 1.2170e-06, 1.7609e-10, 1.3807e-08,\n",
       "        3.0896e-05, 3.8291e-10, 3.7713e-13, 2.7728e-14],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gnnExplainer.train_utils' from '/home/minhvu/GCN/NIPS2020/PGM_Graph/gnnExplainer/train_utils.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(train_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from gnnExplainer import train_utils\n",
    "\n",
    "class ExplainModule(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        graph,\n",
    "        model,\n",
    "        label,\n",
    "        nfeat,\n",
    "        efeat,\n",
    "        snorm_n,\n",
    "        snorm_e,\n",
    "        use_sigmoid=True,\n",
    "    ):\n",
    "        super(ExplainModule, self).__init__()\n",
    "        self.graph = graph\n",
    "        self.model = model\n",
    "        self.label = label\n",
    "        self.nfeat = nfeat\n",
    "        self.efeat = efeat\n",
    "        self.snorm_n = snorm_n\n",
    "        self.snorm_e = snorm_e\n",
    "        self.mask_act = \"sigmoid\"\n",
    "        self.use_sigmoid = use_sigmoid\n",
    "\n",
    "        num_nodes = graph.number_of_nodes()\n",
    "        \n",
    "        self.mask = self.construct_edge_mask(num_nodes, init_strategy=\"const\")\n",
    "        self.feat_mask = self.construct_feat_mask(nfeat.size(-1), init_strategy=\"constant\")\n",
    "        params = [self.mask, self.feat_mask]\n",
    "\n",
    "        self.diag_mask = torch.ones(num_nodes, num_nodes) - torch.eye(num_nodes)\n",
    "        self.scheduler, self.optimizer = train_utils.build_optimizer_(params)\n",
    "\n",
    "        self.coeffs = {\n",
    "            \"size\": 0.005,\n",
    "            \"feat_size\": 1.0,\n",
    "            \"ent\": 1.0,\n",
    "            \"feat_ent\": 0.1,\n",
    "            \"grad\": 0,\n",
    "            \"lap\": 1.0,\n",
    "        }\n",
    "\n",
    "    def construct_feat_mask(self, feat_dim, init_strategy=\"normal\"):\n",
    "        mask = nn.Parameter(torch.FloatTensor(feat_dim))\n",
    "        if init_strategy == \"normal\":\n",
    "            std = 0.1\n",
    "            with torch.no_grad():\n",
    "                mask.normal_(1.0, std)\n",
    "        elif init_strategy == \"constant\":\n",
    "            with torch.no_grad():\n",
    "                nn.init.constant_(mask, 0.0)\n",
    "                # mask[0] = 2\n",
    "        return mask\n",
    "\n",
    "    def construct_edge_mask(self, num_nodes, init_strategy=\"normal\", const_val=1.0):\n",
    "        mask = nn.Parameter(torch.FloatTensor(num_nodes, num_nodes))\n",
    "        if init_strategy == \"normal\":\n",
    "            std = nn.init.calculate_gain(\"relu\") * math.sqrt(\n",
    "                2.0 / (num_nodes + num_nodes)\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                mask.normal_(1.0, std)\n",
    "        elif init_strategy == \"const\":\n",
    "            nn.init.constant_(mask, const_val)\n",
    "\n",
    "        return mask\n",
    "    \n",
    "    def _masked_adj(self):\n",
    "        sym_mask = self.mask\n",
    "        if self.mask_act == \"sigmoid\":\n",
    "            sym_mask = torch.sigmoid(self.mask)\n",
    "        elif self.mask_act == \"ReLU\":\n",
    "            sym_mask = nn.ReLU()(self.mask)\n",
    "        sym_mask = (sym_mask + sym_mask.t()) / 2\n",
    "        adj = self.graph.adjacency_matrix(transpose = False).to_dense()\n",
    "        masked_adj = adj * sym_mask\n",
    "\n",
    "        return masked_adj * self.diag_mask\n",
    "         \n",
    "    def mask_density(self):\n",
    "        mask_sum = torch.sum(self._masked_adj()).cpu()\n",
    "        adj_sum = torch.sum(self.adj)\n",
    "        return mask_sum / adj_sum\n",
    "\n",
    "    def forward(self, unconstrained=False, mask_features=True, marginalize=False):\n",
    "        x = self.nfeat[0]\n",
    "        \n",
    "        if unconstrained:\n",
    "            sym_mask = torch.sigmoid(self.mask) if self.use_sigmoid else self.mask\n",
    "            self.masked_adj = (\n",
    "                torch.unsqueeze((sym_mask + sym_mask.t()) / 2, 0) * self.diag_mask\n",
    "            )\n",
    "        else:\n",
    "            self.masked_adj = self._masked_adj()\n",
    "            if mask_features:\n",
    "                feat_mask = (\n",
    "                    torch.sigmoid(self.feat_mask)\n",
    "                    if self.use_sigmoid\n",
    "                    else self.feat_mask\n",
    "                )\n",
    "                if marginalize:\n",
    "                    std_tensor = torch.ones_like(x, dtype=torch.float) / 2\n",
    "                    mean_tensor = torch.zeros_like(x, dtype=torch.float) - x\n",
    "                    z = torch.normal(mean=mean_tensor, std=std_tensor)\n",
    "                    x = x + z * (1 - feat_mask)\n",
    "                else:\n",
    "                    x = x * feat_mask\n",
    "        \n",
    "        pred = self.model.forward(g, \n",
    "                             x,\n",
    "                             self.efeat,\n",
    "                             self.snorm_n, \n",
    "                             self.snorm_e)\n",
    "    \n",
    "        res = nn.Softmax(dim=0)(pred[0])\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_node = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 7, [57, 73, 24], [0.5161133, 0.33935547, 0.78564453], [0.6333008, 0.67626953, 0.91064453]]\n",
      "[1, 2, [69, 38], [0.7182617, 0.7548828], [0.34594727, 0.5229492]]\n",
      "[2, 1, [44, 5, 13], [0.4855957, 0.05355835, 0.625], [0.51171875, 0.33935547, 0.91064453]]\n",
      "[3, 0, [19, 51, 7], [0.4465332, 0.14282227, 0.46435547], [0.31420898, 0.14282227, 0.4477539]]\n",
      "[4, 4, [68, 42, 35], [0.46435547, 0.22851562, 0.47094727], [0.6430664, 0.6855469, 0.28125]]\n",
      "[5, 1, [61], [0.2529297], [0.6010742]]\n",
      "[6, 4, [40, 50], [0.4741211, 0.4675293], [0.5654297, 0.3310547]]\n",
      "[7, 9, [5, 16, 48, 3], [0.23571777, 0.14282227, 0.035705566, 0.78564453], [0.43579102, 0.91064453, 0.91064453, 0.25]]\n",
      "[8, 5, [62, 60], [0.7319336, 0.2142334], [0.6069336, 0.80371094]]\n",
      "[9, 9, [29, 40], [0.14282227, 0.29296875], [0.25, 0.54296875]]\n"
     ]
    }
   ],
   "source": [
    "index_to_explain = range(10)\n",
    "Explanations = []\n",
    "for iter, (graph, label, snorm_n, snorm_e) in enumerate(test_loader):\n",
    "    if iter in index_to_explain:\n",
    "        pred = model.forward(graph, graph.ndata['feat'],graph.edata['feat'],snorm_n, snorm_e)\n",
    "        soft_pred = np.asarray(softmax(np.asarray(pred[0].data)))\n",
    "        pred_threshold = 0.1*np.max(soft_pred)\n",
    "        e = pe.Graph_Explainer(model, graph, \n",
    "                               snorm_n = snorm_n, snorm_e = snorm_n, \n",
    "                               perturb_feature_list = [0],\n",
    "                               perturb_mode = \"mean\",\n",
    "                               perturb_indicator = \"abs\")\n",
    "        pgm_nodes, p_values, candidates = e.explain(num_samples = 400, percentage = 20, \n",
    "                                top_node = 4, p_threshold = 0.05, pred_threshold = pred_threshold)\n",
    "        label = np.argmax(soft_pred)\n",
    "        pgm_nodes_filter = [i for i in pgm_nodes if p_values[i] < 0.02]\n",
    "        x_cor = [e.X_feat[node_][1] for node_ in pgm_nodes_filter]\n",
    "        y_cor = [e.X_feat[node_][2] for node_ in pgm_nodes_filter]\n",
    "        result = [iter, label, pgm_nodes_filter, x_cor, y_cor]\n",
    "        print(result)\n",
    "        Explanations.append(result)\n",
    "#         savedir = 'result/explanations_'+ str(prog_args.start) + \"_\" + str(prog_args.end) +\".txt\"\n",
    "#         with open(savedir, \"a\") as text_file:\n",
    "#             text_file.write(str(result) + \"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(g.ndata['feat'][0,0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
